{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities\n",
    "### Introduction\n",
    "\n",
    "- Statistics and probability theory constitute a branch of mathematics for dealing with uncertainty. The probability theory provides a basis for the science of statistical inference from data\n",
    "- Sample: (of size n) obtained from a mother population assumed to be represented by a probability\n",
    "- Descriptive statistics: description of the sample\n",
    "- Inferential statistics: making a decision or an inference from a sample of our problem\n",
    "\n",
    "### Probabilities\n",
    "\n",
    "A set of probability values for an experiment with sample space $S = \\\\{ O_1, O_2, \\cdots, O_n \\\\}$  consists of some probabilities that satisfy: $$ 0 \\leq p_i \\leq 1, \\hspace{0.5cm} i= 1,2, \\cdots, n $$ and\n",
    "$$ p_1 + p_2 + \\cdots +p_n = 1 $$\n",
    "\n",
    "The probability of outcome $O_i$ occurring is said to be $p_i$ and it is written:\n",
    "\n",
    "$$ P(O_i) = p_i $$\n",
    "\n",
    "In cases in which the $n$ outcomes are equally likely, then each probability will have a value of $\\frac{1}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events\n",
    "- Events: subset of the sample space\n",
    "- The probability of an event $A$, $P(A)$, is obtained by the probabilities of the outcomes contained withing the event $A$\n",
    "- An event is said to occur if one of the outcomes contained within the event occurs\n",
    "- Complement of events: event $ A' $ is the event consisting of everything in the sample space $S$ that is not contained within $A$: $$\n",
    "P(A) + P(A ') = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations of Events\n",
    "\n",
    "1. Intersections\n",
    "- $A \\cap B$ consists of the outcomes contained within both events $A$ and $B$\n",
    "- Probability of the intersection, $P(A \\cap B) $, is the probability that both events occur simultaneously\n",
    "- Properties:\n",
    "    - $P(A \\cap B) +P(A \\cap B') = P(A)$\n",
    "    - Mutually exclusive events: if $A \\cap B = \\emptyset$\n",
    "    - $A \\cap (B \\cap C) = (A \\cap B) \\cap C $\n",
    "2. Union\n",
    "- Union of Events: $ A \\cup B $ consists of the outcomes that are contained within at least one of the events $A$ and $B$\n",
    "- The probability of this event, $P (A \\cup B)$ is the probability that at least one of these events $A$ and $B$ occurs\n",
    "- Properties:\n",
    "    - If the events are mutually exclusive, then $P(A \\cup B) = P(A) + P(B)$\n",
    "    - $P( A \\cup B) = P(A \\cap B') + P(A' \\cap B) + P(A \\cap B)$\n",
    "    - $P( A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
    "    - $P(A \\cup B \\cup C) = P(A) + P(B) + P(C) - P(A \\cap B) - P( B \\cap C) - P( A \\cap C) + P(A \\cap B \\cap C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "- Conditional Probability: of an event $A$ conditional on an event $B$ is:\n",
    "$$P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\hspace{0.5cm}  \\text{for } P(B) >0$$\n",
    "- Properties:\n",
    "    - $P (A \\mid B) = \\frac{P(A \\cap B)}{P(B)} \\Longrightarrow P(A \\cap B) = P(B)P (A \\mid B)$\n",
    "    - $P (A \\mid B \\cap C) = \\frac{P(A \\cap B \\cap C)}{P(B \\cap C)} \\Longrightarrow P(A \\cap B \\cap C) = P(B \\cap C)P (A \\mid B \\cap C)$\n",
    "    - In general, for a sequence of events $A_1, A_2, \\cdots, A_n$:\n",
    "    $$P(A_1, A_2, \\cdots, A_n) = P(A_1)P(A_2 \\mid A_1)P(A_3 \\mid A_1 \\cap A_2) \\cdots P(A_n \\mid A_1 \\cap \\cdots \\cap A_{n-1})$$\n",
    "- Two events A and B are independent if\n",
    "    - $P(A \\mid B) = P(A)$\n",
    "    - $P(B \\mid A) = P(B)$\n",
    "    - $P(A \\cap B) = P(A) \\times P(B)$\n",
    "    - Interpretation: events are independent if the knowledge about one event does not affect the probability of the other event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Probabilities\n",
    "- Law of total probability: Given $\\{ A_1, A_2, \\cdots, A_n \\}$ a partition of sample space $S$, the probability of an event $B$, $P(B)$ can be expressed as:\n",
    "$$P(B) = \\sum_{i=1}^n P(A_i)P(B \\mid A_i)$$\n",
    "- Bayes' Theorem: Given $\\{ A_1, A_2, \\cdots, A_n \\}$ a partition of a sample space, then the posterior probabilities of the event $A_i$ conditional on an event $B$ can be obtained from the probabilities $P(A_i)$ and $P(A_i \\mid B)$ using the formula:\n",
    "$$ P(A_i \\mid B) = \\frac{P(A_i)P(B \\mid A_i)}{\\sum_{j=1}^n P(A_j)P(B \\mid A_j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"toy\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spam = ['send us your password', 'review our website', 'send your password', 'send us your account']\n",
    "train_ham = ['Your activity report','benefits physical activity', 'the importance vows']\n",
    "test_emails = {'spam':['renew your password', 'renew your vows'], 'ham':['benefits of our account', 'the importance of physical activity']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send', 'your', 'us', 'website', 'account', 'our', 'review', 'password']\n"
     ]
    }
   ],
   "source": [
    "# make a vocabulary of unique words that occur in known spam emails\n",
    "vocab_words_spam = []\n",
    "\n",
    "for sentence in train_spam:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_spam.append(word)     \n",
    "vocab_words_spam = list(set(vocab_words_spam))\n",
    "\n",
    "print(vocab_words_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'benefits', 'activity', 'report', 'physical', 'Your', 'importance', 'vows']\n"
     ]
    }
   ],
   "source": [
    "vocab_words_ham = []\n",
    "\n",
    "for sentence in train_ham:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_ham.append(word)\n",
    "vocab_words_ham = list(set(vocab_words_ham))\n",
    "\n",
    "print(vocab_words_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Discrete)\n",
    "\n",
    "The idea of this project is to write a simple Naive Bayes model to predict if a SMS message is spam or not.\n",
    "Let us derive the necessary probabilities.\n",
    "Naive Bayes is a models that relies on the Bayes' theorem:\n",
    "\n",
    "$$\n",
    "P(Y|X) = \\frac{P(X|Y)\\times P(Y)}{P(X)}\n",
    "$$\n",
    "\n",
    "For this dataset we can write the equation as:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P(y|W_1, ... W_n) &= \\frac{P(W_0, ... W_n|y)\\times P(y)}{P(W_1, ... W_n)} \\\\\n",
    "P(y|W_1, ... W_n) &= \\frac{P(W_0 | W_1, ... W_n,y)\\times ...\\times P(y)}{P(W_0, ... W_n)} \\\\\n",
    "P(y|W_1, ... W_n) &= \\frac{P(y) \\times \\prod_{i=0}^{n}P(W_i|y)}{P(W_0, ... W_n)} \\\\\n",
    "P(y|W_1, ... W_n) &= \\frac{P(y) \\times \\prod_{i=0}^{n}P(W_i|y)}{P(y) \\times \\prod_{i=0}^{n}P(W_i|y) + P(\\neg y) \\times \\prod_{i=0}^{n}P(W_i|\\neg y)}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(vocab, train):\n",
    "    likelihood = {}\n",
    "    for w in vocab:\n",
    "        count = 0\n",
    "        for sentence in train:\n",
    "            if w in sentence:\n",
    "                #print(w+\":\", sentence)\n",
    "                count += 1\n",
    "        print(f\"Number of ham emails with the word '{w}': {count}\")\n",
    "        prob = (count + 1)/(len(train) + 2) # smoothing\n",
    "        print(f\"Hamicity of the word '{w}': {prob} \")\n",
    "        likelihood[w.lower()] = prob\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ham emails with the word 'send': 3\n",
      "Hamicity of the word 'send': 0.6666666666666666 \n",
      "Number of ham emails with the word 'your': 3\n",
      "Hamicity of the word 'your': 0.6666666666666666 \n",
      "Number of ham emails with the word 'us': 2\n",
      "Hamicity of the word 'us': 0.5 \n",
      "Number of ham emails with the word 'website': 1\n",
      "Hamicity of the word 'website': 0.3333333333333333 \n",
      "Number of ham emails with the word 'account': 1\n",
      "Hamicity of the word 'account': 0.3333333333333333 \n",
      "Number of ham emails with the word 'our': 4\n",
      "Hamicity of the word 'our': 0.8333333333333334 \n",
      "Number of ham emails with the word 'review': 1\n",
      "Hamicity of the word 'review': 0.3333333333333333 \n",
      "Number of ham emails with the word 'password': 2\n",
      "Hamicity of the word 'password': 0.5 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'send': 0.6666666666666666,\n",
       " 'your': 0.6666666666666666,\n",
       " 'us': 0.5,\n",
       " 'website': 0.3333333333333333,\n",
       " 'account': 0.3333333333333333,\n",
       " 'our': 0.8333333333333334,\n",
       " 'review': 0.3333333333333333,\n",
       " 'password': 0.5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_spam = compute_likelihood(vocab_words_spam, train_spam)\n",
    "likelihood_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ham emails with the word 'the': 1\n",
      "Hamicity of the word 'the': 0.4 \n",
      "Number of ham emails with the word 'benefits': 1\n",
      "Hamicity of the word 'benefits': 0.4 \n",
      "Number of ham emails with the word 'activity': 2\n",
      "Hamicity of the word 'activity': 0.6 \n",
      "Number of ham emails with the word 'report': 1\n",
      "Hamicity of the word 'report': 0.4 \n",
      "Number of ham emails with the word 'physical': 1\n",
      "Hamicity of the word 'physical': 0.4 \n",
      "Number of ham emails with the word 'Your': 1\n",
      "Hamicity of the word 'Your': 0.4 \n",
      "Number of ham emails with the word 'importance': 1\n",
      "Hamicity of the word 'importance': 0.4 \n",
      "Number of ham emails with the word 'vows': 1\n",
      "Hamicity of the word 'vows': 0.4 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 0.4,\n",
       " 'benefits': 0.4,\n",
       " 'activity': 0.6,\n",
       " 'report': 0.4,\n",
       " 'physical': 0.4,\n",
       " 'your': 0.4,\n",
       " 'importance': 0.4,\n",
       " 'vows': 0.4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_ham = compute_likelihood(vocab_words_ham, train_ham)\n",
    "likelihood_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the prior probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior prob HAM: 0.5714285714285714\n",
      "Prior prob HAM: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "prior_spam = len(train_spam) / (len(train_spam)+(len(train_ham)))\n",
    "print(f'Prior prob HAM: {prior_spam}')\n",
    "prior_ham = len(train_ham) / (len(train_spam)+(len(train_ham)))\n",
    "print(f'Prior prob HAM: {prior_ham}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Prior Pos and Likelihood probabilities using Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def Bayes(txt):\n",
    "    probs_spam = []\n",
    "    probs_ham = []\n",
    "\n",
    "    txt_as_list = txt.split()\n",
    "    for w in txt_as_list:\n",
    "        if w in likelihood_spam:\n",
    "            pr_WS = likelihood_spam[w]\n",
    "        else:\n",
    "            pr_WS = 1.0/(len(train_spam)+2)\n",
    "        \n",
    "        if w in likelihood_ham:\n",
    "            pr_WH = likelihood_ham[w]\n",
    "        else:\n",
    "            pr_WH = 1.0/(len(train_ham)+2)\n",
    "        \n",
    "        probs_spam.append(pr_WS)\n",
    "        probs_ham.append(pr_WH)\n",
    "    \n",
    "    p_if_spam = prior_spam * reduce(lambda num1, num2: num1 * num2, probs_spam, 1.0)\n",
    "    p_if_ham = prior_ham * reduce(lambda num1, num2: num1 * num2, probs_ham, 1.0)\n",
    "    return p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classigy the \"toy\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send us your password -> 0.9788566953797965\n",
      "review our website -> 0.9391435011269722\n",
      "send your password -> 0.9487666034155597\n",
      "send us your account -> 0.9686168151879117\n"
     ]
    }
   ],
   "source": [
    "for sentence in train_spam:\n",
    "    prob_spam = Bayes(sentence)\n",
    "    print(f'{sentence} -> {prob_spam}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your activity report -> 0.11394712853236098\n",
      "benefits physical activity -> 0.06041565973900434\n",
      "the importance vows -> 0.08796622097114706\n"
     ]
    }
   ],
   "source": [
    "for sentence in train_ham:\n",
    "    prob_spam = Bayes(sentence)\n",
    "    print(f'{sentence} -> {prob_spam}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
